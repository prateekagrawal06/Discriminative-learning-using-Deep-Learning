{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import os\n",
    "from pylab import *\n",
    "#from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##computes accuray \n",
    "\n",
    "def accuracy(Y,Y_hat):                \n",
    "    sum1 = sum([1 for i in range(len(Y)) if Y[i] != Y_hat[i]])\n",
    "    return sum1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##coverts fetures in nin linear space\n",
    "def define_Z(X,d):\n",
    "    poly = PolynomialFeatures(d)\n",
    "    Z = poly.fit_transform(X)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##taken from internet to shuffle two numpy array in Unision\n",
    "\n",
    "def shuffle_in_unison(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    shuffled_a = np.empty(a.shape, dtype=a.dtype)\n",
    "    shuffled_b = np.empty(b.shape, dtype=b.dtype)\n",
    "    permutation = np.random.permutation(len(a))\n",
    "    for old_index, new_index in enumerate(permutation):\n",
    "        shuffled_a[new_index] = a[old_index]\n",
    "        shuffled_b[new_index] = b[old_index]\n",
    "    return shuffled_a, shuffled_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## indication function to return 1 and O depending on the class\n",
    "\n",
    "def indicator(y,cls):\n",
    "    if y==cls:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Softmax function returning a value between 0 and 1\n",
    "\n",
    "def softmax(V,z,k):\n",
    "    \n",
    "    \n",
    "    #print z.shape\n",
    "    d = 0\n",
    "    for v in V:\n",
    "        \n",
    "        #print v.shape\n",
    "        \n",
    "        d += exp(np.dot(np.transpose(v),z))\n",
    "    n = exp(np.dot(np.transpose(V[k]),z))\n",
    "    return (1.*n/d)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##sigmoid function returnin value between zero and one\n",
    "def sigmoid(w,x):\n",
    "    \n",
    "    return (1/(1 + exp(-np.dot(np.transpose(w),x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##computes value of Y and Z on the basis of the estimated parameter\n",
    "\n",
    "def compute_Z_Y(X,W,V):\n",
    "    \n",
    "    Z = []\n",
    "    \n",
    "    Y_hat = []\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        \n",
    "        z = [1.0]\n",
    "        \n",
    "        y = []\n",
    "        \n",
    "        for w in W:\n",
    "        \n",
    "            z.append(sigmoid(w,X[i]))\n",
    "        \n",
    "        Z.append(z)          \n",
    "            \n",
    "        for k in range(V.shape[0]):\n",
    "            \n",
    "            #print k\n",
    "            \n",
    "            y.append(softmax(V,z,k))\n",
    "            \n",
    "            #print y\n",
    "        \n",
    "        Y_hat.append(y)\n",
    "        \n",
    "    #print Z\n",
    "    #print Y_hat\n",
    "              \n",
    "    return np.array(Z),np.array(Y_hat)\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##computes likelihood for the predicted value of Y\n",
    "def likelihood(X,Y,K,Y_hat):\n",
    "    \n",
    "    l = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        for k in range(K):\n",
    "            l += indicator(Y[i],k) * (log10(Y_hat[i][k]))\n",
    "    l = - l\n",
    "    return l\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##main training function \n",
    "##takes X Y H and learning rate as input and returns pewsicted value of Z and Y\n",
    "\n",
    "def training(X,Y,cat,H,lr):\n",
    "    \n",
    "    W = np.zeros(shape=(H,X.shape[1]))\n",
    "    \n",
    "    W.fill(0.00)\n",
    "    \n",
    "    K = len(cat)\n",
    "    \n",
    "    V = np.zeros(shape=(K,H+1))\n",
    "    \n",
    "    V.fill(0.00)\n",
    "    \n",
    "    Z,Y_hat = compute_Z_Y(X,W,V)\n",
    "    \n",
    "    l_new = likelihood(X,Y,K,Y_hat)\n",
    "    \n",
    "    it = 0\n",
    "    \n",
    "    best = False\n",
    "    \n",
    "    while best == False: \n",
    "        \n",
    "        l_pre = l_new\n",
    "        \n",
    "    \n",
    "        for k in range(K):\n",
    "\n",
    "            grad_V = 0\n",
    "\n",
    "            for i in range(X.shape[0]):\n",
    "\n",
    "                grad_V += (Y_hat[i][k] - indicator(Y[i],k))* Z[i]\n",
    "\n",
    "            #print grad_V\n",
    "\n",
    "            V[k] = V[k] - (lr*grad_V)\n",
    "\n",
    "\n",
    "\n",
    "        for h in range(H):\n",
    "\n",
    "            grad_W = 0\n",
    "\n",
    "            for i in range(X.shape[0]):\n",
    "\n",
    "                x = 0\n",
    "\n",
    "                for k in range(K):\n",
    "\n",
    "                    x += (Y_hat[i][k] - indicator(Y[i],k)) * V[k][h+1]\n",
    "\n",
    "\n",
    "                    grad_W +=  x * Z[i][h+1] * (1.0 - Z[i][h+1]) * X[i]\n",
    "\n",
    "                W[h] = W[h] - lr*grad_W\n",
    "\n",
    "\n",
    "        Z,Y_hat = compute_Z_Y(X,W,V)\n",
    "\n",
    "        it += 1\n",
    "\n",
    "        l_new = likelihood(X,Y,K,Y_hat)\n",
    "        \n",
    "        print l_new\n",
    "        \n",
    "        if it==100 or abs(l_new-l_pre) < 0.5:\n",
    "            \n",
    "            best = True\n",
    "        \n",
    "        \n",
    "    return V,W,Y_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##computers the actual lable of Y (Eg: 0, 1 or 2)\n",
    "\n",
    "def compute_Y_pred(Y_hat):\n",
    "    Y_pred = []\n",
    "    for y_hat in Y_hat:\n",
    "        #print y_hat\n",
    "        \n",
    "        Y_pred.append(np.argmax(y_hat))\n",
    "            \n",
    "    return np.reshape(np.array(Y_pred),(len(Y_pred),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##fetching the data from Sklearn package for classification only fro digit 0,1 and 2\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "\n",
    "x, y = mnist.data / 255., mnist.target\n",
    "X = []\n",
    "Y = []\n",
    "for i in range(len(y)):\n",
    "    if y[i] == 0.0 or y[i] == 1.0 or y[i] == 2.0:\n",
    "        X.append(x[i])\n",
    "        Y.append(y[i])\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "print X.shape\n",
    "X = define_Z(X,1)\n",
    "cat = (set(Y))\n",
    "Y = np.reshape(np.array(Y),(len(Y),1))\n",
    "\n",
    "X,Y = shuffle_in_unison(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### training and estimating parameters for 1000 rows\n",
    "V,W,Y_hat = training(X[:1000],Y[:1000],cat,100,0.000001)\n",
    "Y_pred = compute_Y_pred(Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Traning error\", accuracy(Y[:1000],Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## predicting the value for next 500 observations\n",
    "Z_test,Y_hat_test = compute_Z_Y(X[1000:1500],W,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred_test = compute_Y_pred(Y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"testing error\", accuracy(Y[1000:1500],Y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################## actual MLP implementation######################################\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=10, alpha=1e-4,\n",
    "                    algorithm='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(X[:1000], y_train[:1000])\n",
    "print(\"Training set accuracy: %f\" % mlp.score(X[:1000], y_train[:1000]))\n",
    "print(\"Test set score: %f\" % mlp.score(X[:500], y_test[:5000]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
